\documentclass[11pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{listings}		% for \lstlisting
\usepackage[left=3cm,right=3cm,top=3cm,bottom=3cm]{geometry}
\usepackage{hyperref}		% for clickeable table of contents

\newcommand{\pgl}[1]{\textsf{#1}}
\newcommand{\perltoc}[2]{
Perl:
\begin{lstlisting}[language=perl]
aa
\end{lstlisting}

C:
\begin{lstlisting}[language=C]
bb
\end{lstlisting}
}
\newcommand{\bash}[1]{\texttt{#1}}
\newcommand{\regexp}[1]{$#1$}
\newcommand{\smalldfa}[2]{
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.7]{#1}
	\caption{#2}
\end{figure}
}
\newcommand{\largedfa}[2]{
\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{#1}
	\caption{#2}
\end{figure}
}

\title{Conq: A Perl to C compiler}
\author{Hugo Kapp}

\begin{document}

\maketitle

% Here goes the text for the preface

\tableofcontents

\chapter*{Introduction}

Perl is a famous scripting language, mostly used for text handling. It provides regular expressions as part of its core elements, and permits easy rewriting of text files, loading of config files, csv building / extraction ...

Perl is an interpreted language. The main reason for this is the fact that it is a scripting language in the pure tradition of \pgl{sh} or \pgl{python}. This means that it is dynamically typed, and runtime checks must be performed to figure out the semantics of every basic operator. This is easier done in an interpreter than in machine code.

Having an interpreter has the disadvantage of being slow when executing regular expression matching. This gives poor performance for regular expression heavy programs, which is supposed to be the core of Perl.

%This implies poor performance for programs that don't use variables, or in which variables never change type. To this end, we want to provide an alternative to the classic Perl interpreter for these use cases.

We describe an alternative, called Conq. Conq is a Perl to C compiler. This means we can compile Perl programs down to machine code, improving the performance of regular expression matching. Later, we may also investigate runtime specialization to address the performance issues related to runtime type dispatch.

\chapter{Goals}

\section{Efficient regular expression matching}

The main point we want to address is the translation from regular expression to efficient machine code. We value this aspect for the following reasons :
\begin{itemize}
\item This is the part where we believe we can achieve the biggest improvement over the current Perl interpreter
\item This is the most interesting part to work on
\end{itemize}

\section{Runtime specialization}

An orthogonal point we could investigate is linked to runtime specialization. There are indeed a lot of room for optimization with runtime specialization in Perl scripts.

One case of such optimizations opportunities is regarding variables and operator typing. Due to the dynamically-typed nature of Perl, each operator must, at runtime, check which types its operand are, and apply the correct semantics with regard to this type. This means that, if $a = a + b$ must be executed, then in the case where $a$ and $b$ are both integers the program would perform addition, but if $a$ and $b$ are strings, then the operation is a concatenation. This typing information is only available at runtime.

Lots of things can be done in the case described above. First, we can profile the input types to this $+$ operator. If they are always the same, we can replace the operator runtime checks by the actual code for the correct semantics.

We can also profile the types of the variables $a$ and $b$. If they never change, we can actually replace the code of every operator using $a$ and $b$.

Another place for runtime specialization in Perl scripts comes from dynamic regular expressions. Consider the following program : $/aab\$d/$. Different scenarios may arise from the previous example :
\begin{enumerate}
\item $d$ is a program constant \\
The regular expression can be compiled down to machine code\\
This can be done with static analysis
\item $d$ is a per-execution constant \\
The regular expression can be compiled down to machine code for each execution of the program (only useful if executed more than once)\\
This can be found out statically, but the code must be generated at runtime
\item $d$ is not constant, but always evaluates to the same value at runtime \\
This can only be found out at runtime using profiling \\
Machine code (with guards) can be generated at runtime
\item $d$ may have multiple values at runtime \\
Nothing can be done. A generic and inefficient version must be generated ahead of time
\end{enumerate}

Case 1 can be done completely ahead of time. Case 2 must generate the code at runtime, but the information can already be given ahead of time. Case 3 must be done at runtime (not guaranteed to yield results though).

The lifespan of these specializations is not determined yet. It may either be :
\begin{itemize}
\item Per execution \\
This has the advantage of reflecting the types of the currently executing program, but must be reexecuted everytime and makes the specialization process hard to write (code rewriting during execution)
\item Per script \\
In this variant, runtime information is gathered during execution, and specialized code generated at the end of the execution, then recompiled\\
This makes the specialization process easier to write, and allows subsequent executions of the same scripts to be faster right away.
\end{itemize}

Because it is simpler to write and makes a lot of sense (we believe variables used by the programmer always have the same meaning between executions, i.e. always the same type), we might rather go for the second option.

Generally, we consider runtime specialization to be a late optimization in the development process.

\section{Provide a viable replacement for Perl}

Eventually, this means providing all the options \pgl{Perl} does. The most important here might be the in-line script definition, i.e. \bash{perl -e 's/aa/a/g'}.

One other important aspect of \pgl{Perl} we must provide is the reading from files (also from stdin).

\section{Roadmap for language support}

The roadmap for language support should be the following :
\begin{enumerate}
\item Regular expressions
	\begin{enumerate}
	\item Simple regular expression matching
	\item Static replacements
	\item Complete regular expression matching
	\item Dynamic replacements	
	\end{enumerate}
\item Scripting
	\begin{enumerate}
	\item Global variables
	\item Variables assigned regular expression results
	\item Printing
	\item Basic operators
	\item Control flow
	\item stdin handling
	\item File handling
	\end{enumerate}
\end{enumerate}

\chapter{Regular expressions to DFA}

There is already theory about how to represent a regular expression as a DFA. It is easier to turn the regexp into a NFA, and then use basic rules to transform the latter into a DFA.

\section{Regular expressions to NFA}

\label{regexptonfa}

We provide here a recap of how the various elements of a regular expression can be transformed into an NFA.

In regular expressions, small letters $a$, $b$, ... are single letters in the regular expressions, while CAPS letters $A$, $B$, ... represent sub-regular expression.

\subsubsection{Concatenation}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.7]{./img/nfa/concat.png}
	\caption{NFA for \regexp{A|B}}
\end{figure}

\subsubsection{Option}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.7]{./img/nfa/option.png}
	\caption{NFA for \regexp{A?}}
\end{figure}

\subsubsection{Repetitions}

There are multiple kinds of repetition, though we can desugar most of them into simpler elements.

The basic repetition, the $'*'$ operator, also called the \textit{Kleene star}, accepts any number of repetitions of the subexpression. 0 repetitions is accepted by Kleene star.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.7]{./img/nfa/kleene-star.png}
	\caption{NFA for \regexp{A*}}
\end{figure}

All other repetition operators can be expressed using Kleene star, which makes it the only required repetition operator.

The $'+'$ repetition operator requires at least one repetition of the given subexpression. \regexp{A+} can be rewritten as \regexp{AA*}.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.7]{./img/nfa/repeat-at-least-once.png}
	\caption{NFA for \regexp{A+}. This is equivalent to \regexp{AA*}}
\end{figure}

The "repeat n times" operator has the following syntax : \regexp{A\{n\}}. This can be rewritten as n concatenations of $A$, e.g. \regexp{A\{n\} = AA..A\ (n\ times)}.

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{./img/nfa/repeat-n-times.png}
	\caption{NFA for \regexp{A\{n\}}. This is equivalent to \regexp{AA..A\ (n\ times)}}
\end{figure}

Note however that we might prefer to do a C-loop in this case rather than copying n times the code, to avoid code explosion. Copying it would then be a loop unrolling optimization, which can be decided based on other information.

The "repeat at least n times" operator is written \regexp{A\{n,\}}. It can be rewritten using \regexp{A\{n\}} and Kleene star : \regexp{A\{n,\} = A\{n\}A* = AA..AA*}.

Note that \regexp{A\{1,\} = A+}. This can easily be seen by comparing the rewritten expression for both operators.

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{./img/nfa/repeat-at-least-n-times.png}
	\caption{NFA for \regexp{A\{n,\}}. This is equivalent to \regexp{A\{n\}A*}}
\end{figure}

The "repeat at most m times" operator is the complement of the previous, and is written as \regexp{A\{,m\}}. It can be rewritten as \regexp{A?A?...A?\ (m\ times)}.

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{./img/nfa/repeat-at-most-m-times.png}
	\caption{NFA for \regexp{A\{,m\}}. This is equivalent to \regexp{A?A?...A?\ (m\ times)}}
\end{figure}

Same comment here about loop unrolling as made regarding \regexp{A\{n\}}. Note also that \regexp{A\{,1\} = A?}

The last repetition operator puts lower and upper bounds on the number of repetitions. "Repeat between n and m times" is written as \regexp{A\{n, m\}}. As one can guess from the syntax and semantics, \regexp{A\{n, m\}} is rewritten using \regexp{A\{n, \}} and \regexp{A\{, m\}} : \regexp{A\{n, m\} = A\{n, \}A\{, m\}}. The (cumbersome) rewriting into only basic elements is \regexp{A\{n, m\} = AA..AA?A?..A?}

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{./img/nfa/repeat-between-n-and-m-times.png}
	\caption{NFA for \regexp{A\{n,m\}}. This is equivalent to \regexp{A\{n,\}A\{,m\}}}
\end{figure}

With correct rewriting, only the Kleene star operator must be implemented to support all the repetition operators.

\subsubsection{Alternative}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.7]{./img/nfa/alt.png}
	\caption{NFA for \regexp{A|B}}
\end{figure}

\subsubsection{Negation}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.7]{./img/nfa/neg.png}
	\caption{NFA for \regexp{[\ \hat{} A]}}
\end{figure}

\section{From NFA to DFA}

We provide here the simple rules that can be used to turn an NFA into a DFA.

Starting from the NFAs listed in Section \ref{regexptonfa}, we only need to describe a way to translate choice-based patterns from NFAs to DFAs. This yields a small number of patterns :
\begin{itemize}
\item Choice between $A$ and $B$
\item Choice between $A$ and the accepting state
\end{itemize}

To be able to give a translation for these choice-based patterns, we must provide an ordering for the different options. For subexpressions, the ordering is given in the original program : the left-most variant has precedence over the ones on the right. Then, following the "longest match" semantics of regular expressions, subexpressions have precedence over the accepting state.

This is enough to translate all the NFA patterns given above.

\smalldfa{./img/nfa/concat.png}{BB}

\section{From regular expression directly to DFA}

Using the rules defined in the sections above, we give here a direct translation from the basic elements of regular expressions into a DFA. This is what is used in our system.


\chapter{Regular expression compilation}

We lay out in this section the design for the compilation of regular expressions.

\section{Parsing}

\section{Intermediate Representation}

We detail here the representation we use for DFAs inside the system, i.e. our IR.

\section{DFA to C}

\section{Backtracking}

Backtracking must be used when a regular expression specifies an alternative. The first alternative is tested for match, and if it does not, then backtracking must be performed on the stream to test the second alternative.

\section{Filling regexp variables}

Regular expressions define variables that represent a subset of the matched string. We describe here how these are managed in Conq.

\chapter{Scripts compilation}

\chapter{Discussion points}

\section{Source and destination language}

\subsection{Source language}

We have two options here :
\begin{enumerate}
\item Start from source Perl scripts
\item Compile the already anayzed Perl bytecode
\end{enumerate}

\begin{tabular}{|r|l|l|}
\hline
	& Perl scripts	& Perl bytecode \\
\hline
Advantages	& All information about the program	& Already compiled and analyzed source code \\
	&	& Can be integrated in the current Perl interpreter as a runtime compiler \\
\hline
Disadvantages	& Complex parser	& No need to reimplement the parser \\
\hline
\end{tabular}

\subsection{Destination language}

The destination language will mostly depend on the goals pursued. It can be either :
\begin{itemize}
\item A low-level language easily compiled down to machine code (most likely \pgl{C}, could be \pgl{LLVM})
\item Truffle
\end{itemize}

If we want to support a lot of runtime specializations, then it may be easier to go for Truffle (though we might loose on the regular expression part).

On the other hand, writing the runtime specializations by hand is a great learning exercise.

\section{Simple runtime specialization}


Perl:
\begin{lstlisting}[language=perl]
a = a + b;
\end{lstlisting}

C:
\begin{lstlisting}[language=C]
lasttypea;
lasttypeb;
if (a.type == lasttypea \&\& b.type == lasttypeb)
  goto lastjump
else if (a.type == int \&\& b.type == int) {
:plusint
  a = a + b;
  lasttypea=int;
  lasttypeb=int;
  lastjump = plusint;
}
else if (...) {	
...
\end{lstlisting}

\section{Typed operation dispatch}


Perl:
\begin{lstlisting}[language=perl]
a = a + b;
\end{lstlisting}

C:
\begin{lstlisting}[language=C]
pluslabels gotolabels[][] = ...;
goto pluslabels[a.typecode][b.typecode];
\end{lstlisting}

\end{document}